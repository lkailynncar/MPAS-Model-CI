name: (CIRRUS, cisldev) - Build MPAS-A and run 240km test case

# This workflow is used to build and run MPAS-A inside NCAR HPC development containers.
# It's adapted from Ben Kirk's workflows building & testing dev containers with github actions
# NCAR/CISL Docker Hub: https://hub.docker.com/u/ncarcisl
# Ben Kirk's workflows: https://github.com/benkirk/demo_github_actions


on:
  workflow_dispatch:
    inputs:
        os:
          description: 'Base OS'
          type: choice
          required: true
          default: almalinux9
          options:
            - almalinux8
            - almalinux9
            - almalinux10
            - leap
            - tumbleweed
            - noble

jobs:

  #===========================================================================
  # BUILD JOB
  #===========================================================================
  build-mpas:
    strategy:
      fail-fast: false
      max-parallel: 4
      matrix:
        compiler: [ nvhpc, oneapi, gcc ]
        mpi:      [ mpich3, openmpi ]
        gpu:      [ cuda, nogpu ]
        io:       [ smiol, pio ]
        arch:     [ x86_64 ]

        # Skip cuda builds for compilers that don't use OpenACC
        exclude:
          - compiler: gcc
            gpu: cuda
          - compiler: oneapi
            gpu: cuda

        # Map each option value to its environment setup command
        include:
          # MPI mappings
          - mpi: openmpi
            extra_mpi_args: 'export MPI_IMPL=openmpi'
          - mpi: mpich3
            extra_mpi_args: 'export MPI_IMPL=mpich'
          # I/O mappings
          - io: smiol
            extra_io_args: 'unset PIO; export USE_PIO2=false'
          - io: pio
            extra_io_args: 'export PIO_ROOT=${PIO_ROOT:-/container/pio}; export USE_PIO2=true'
          # GPU/accelerator mappings (only nvhpc + cuda enables OpenACC)
          - compiler: nvhpc
            gpu: cuda
            extra_accel_args: 'export OPENACC=true'

    name: Build (${{ matrix.compiler }}, ${{ matrix.mpi }}, ${{ matrix.gpu }}, ${{ matrix.io }})
    runs-on:
      group: CIRRUS-4x8-gpu
    defaults:
      run:
        shell: bash -elo pipefail {0}

    container:
      image: ncarcisl/cisldev-${{ matrix.arch }}-${{ inputs.os }}-${{ matrix.compiler }}-${{ matrix.mpi }}${{ matrix.gpu == 'cuda' && '-cuda' || '' }}:devel
    
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: 'true'
          fetch-depth: 0

      - name: Interrogate Runtime Environment
        run: |
          pwd
          ls
          find -type d
          env
          cat /container/config_env.sh
          df -h
          cat /etc/os-release 2>/dev/null || true
          uname -a
          lscpu
          nvidia-smi 2>/dev/null || true
          echo && echo && echo
          echo '----------------------------------------------------------------'
          echo && echo && echo
          echo "CC=${CC}"
          echo "CXX=${CXX}"
          echo "FC=${FC}"
          echo "F77=${F77}"
          echo
          echo "CFLAGS=${CFLAGS}"
          echo "CPPFLAGS=${CPPFLAGS}"
          echo "CXXFLAGS=${CXXFLAGS}"
          echo "FCFLAGS=${FCFLAGS}"
          echo "F77FLAGS=${F77FLAGS}"
          export CC CXX FC F77 CFLAGS CXXFLAGS FCFLAGS F77FLAGS CPPFLAGS
          which conda 2>/dev/null && conda --version || echo " --> no conda in this container"
          which mpicc
          mpicc --version 2>/dev/null || true

      - name: Build MPAS-A
        continue-on-error: false
        timeout-minutes: 20
        run: |
          chmod +x .github/workflows/build_mpas.sh
          # Use extra_io_args to set whether to use PIO or SMIOL
          if [ -n "${{ matrix.extra_io_args }}" ]; then
            eval "${{ matrix.extra_io_args }}"
          fi
          # Use extra_accel_args to set whether to use OpenACC
          if [ -n "${{ matrix.extra_accel_args }}" ]; then
            eval "${{ matrix.extra_accel_args }}"
          fi
          echo "Build configuration:"
          echo "  USE_PIO2=${USE_PIO2:-not set}"
          echo "  OPENACC=${OPENACC:-not set}"
          timeout 25m .github/workflows/build_mpas.sh

      - name: Upload atmosphere_model executable
        uses: actions/upload-artifact@v4
        with:
          name: atmosphere_model-${{ matrix.compiler }}_${{ matrix.mpi }}_${{ matrix.gpu }}_${{ matrix.io }}
          path: atmosphere_model
  
  #===========================================================================
  # RUN JOB
  #===========================================================================
  run-mpas-240km:
    needs: build-mpas

    strategy:
      fail-fast: false
      max-parallel: 4
      matrix:
        # These must match builds from above (for artifact download)
        compiler: [ nvhpc, oneapi, gcc ]
        mpi:      [ mpich3, openmpi ]
        gpu:      [ cuda, nogpu ]
        io:       [ smiol, pio ]
        arch:     [ x86_64 ]
        # Run-specific options
        num_procs: [ 1 ]

        # Skip cuda runs for compilers that don't use OpenACC (matches build excludes)
        exclude:
          - compiler: gcc
            gpu: cuda
          - compiler: oneapi
            gpu: cuda

        # Map each option value to its environment setup command
        include:
          # MPI mappings
          - mpi: openmpi
            extra_mpi_args: 'export MPI_IMPL=openmpi'
          - mpi: mpich3
            extra_mpi_args: 'export MPI_IMPL=mpich'
          # I/O mappings (needed if run step uses them)
          - io: smiol
            extra_io_args: 'unset PIO; export USE_PIO2=false'
          - io: pio
            extra_io_args: 'export PIO_ROOT=${PIO_ROOT:-/container/pio}; export USE_PIO2=true'

    name: Run 240km (${{ matrix.compiler }}, ${{ matrix.mpi }}, ${{ matrix.gpu }}, ${{ matrix.io }}, ${{ matrix.num_procs }}proc)
    runs-on: 
      group: CIRRUS-4x8-gpu
    defaults:
      run:
        shell: bash -elo pipefail {0}

    container:
      image: ncarcisl/cisldev-${{ matrix.arch }}-${{ inputs.os }}-${{ matrix.compiler }}-${{ matrix.mpi }}${{ matrix.gpu == 'cuda' && '-cuda' || '' }}:devel
    
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: 'true'
          fetch-depth: 0

      - name: Interrogate Runtime Environment
        run: |
          pwd
          ls
          find -type d
          env
          cat /container/config_env.sh
          df -h
          cat /etc/os-release 2>/dev/null || true
          uname -a
          lscpu
          nvidia-smi 2>/dev/null || true
          echo && echo && echo
          echo '----------------------------------------------------------------'
          echo && echo && echo
          echo "CC=${CC}"
          echo "CXX=${CXX}"
          echo "FC=${FC}"
          echo "F77=${F77}"
          echo
          echo "CFLAGS=${CFLAGS}"
          echo "CPPFLAGS=${CPPFLAGS}"
          echo "CXXFLAGS=${CXXFLAGS}"
          echo "FCFLAGS=${FCFLAGS}"
          echo "F77FLAGS=${F77FLAGS}"
          export CC CXX FC F77 CFLAGS CXXFLAGS FCFLAGS F77FLAGS CPPFLAGS
          which conda 2>/dev/null && conda --version || echo " --> no conda in this container"
          which mpicc
          mpicc --version 2>/dev/null || true

      - name: Download atmosphere_model executable
        uses: actions/download-artifact@v4
        with:
          name: atmosphere_model-${{ matrix.compiler }}_${{ matrix.mpi }}_${{ matrix.gpu }}_${{ matrix.io }}

      - name: Make atmosphere_model executable
        run: chmod +x atmosphere_model

      - name: Run MPAS-A 240km case with ${{ matrix.num_procs }} ranks
        continue-on-error: true
        timeout-minutes: 20
        run: |
          chmod +x .github/workflows/run_mpas_240km.sh
          # Use extra_mpi_args to set MPI implementation
          if [ -n "${{ matrix.extra_mpi_args }}" ]; then
            eval "${{ matrix.extra_mpi_args }}"
          fi
          echo "Run configuration:"
          echo "  MPI_IMPL=${MPI_IMPL:-not set}"
          echo "  num_procs=${{ matrix.num_procs }}"
          .github/workflows/run_mpas_240km.sh ${{ matrix.num_procs }}

      - name: Upload log files
        uses: actions/upload-artifact@v4
        with:
          name: mpas_240km_${{ matrix.num_procs }}rank_logs_${{ matrix.compiler }}_${{ matrix.mpi }}_${{ matrix.gpu }}_${{ matrix.io }}
          path: |
            240km_${{ matrix.num_procs }}/log.*

  #===========================================================================
  # VALIDATION JOB: Compare log outputs against reference standard
  #===========================================================================
  validate-results:
    needs: run-mpas-240km
    if: always()
    runs-on: ubuntu-latest
    name: Validate run results
    
    steps:
      - uses: actions/checkout@v4
        with:
          sparse-checkout: .github/workflows/validation

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Download all log artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: mpas_240km_*_logs_*
          path: logs

      - name: List downloaded artifacts
        run: |
          echo "Downloaded log artifacts:"
          ls -la logs/
          find logs -name "*.out" | head -20

      - name: Compare logs against reference
        run: |
          python .github/workflows/validation/compare_logs.py \
            logs \
            .github/workflows/validation/reference_log.atmosphere.0000.out

  #===========================================================================
  # CLEANUP JOB: Deletes executable artifacts after all runs complete
  #===========================================================================
  cleanup-artifacts:
    needs: [run-mpas-240km, validate-results]
    if: always()
    runs-on: ubuntu-latest
    name: Cleanup executable artifacts
    
    steps:
      - name: Delete all executable artifacts
        uses: geekyeggo/delete-artifact@v5
        with:
          name: atmosphere_model-*
          failOnError: false
